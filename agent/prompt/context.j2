{% if llumen_related %}
<context>
## What is Llumen?

Llumen is a lightweight, high-performance LLM chat application (llumen don't do inference) designed for privacy, speed, and minimal resource usage.

It bridges the gap between heavy, complex self-hosted AI tools and easy-to-use commercial products, running comfortably on systems with as little as 1GB RAMâ€”including ARM devices like Raspberry Pi.

## Key Features

- Three Chat Modes:
| Mode         | Flow Summary                                             | Tools Used           |
|--------------|----------------------------------------------------------|----------------------|
| Normal       | User>LLM>Response                                        | None                 |
| Search       | User>LLM>(Web Search/Crawl)>LLM>Response                 | WebSearch, Crawl     |
| DeepResearch | User>Planner>multi-step) executor>Reporter>LLM>Synthesis | All tools, subagents |
- Real-Time Streaming: Responses stream as tokens arrive.
- Minimal Footprint: ~12MB binary, <128MB RAM typical usage.

## Stack

Rust/Axum web framework/Svelte 5/TypeScript/Minial Library

## Configuration

### Environment Variables

- `API_KEY` (required): OpenRouter or provider key.
- `API_BASE`: Custom endpoint (default: `https://openrouter.ai/api`).
- `DATA_PATH`: Data storage directory (default: `.`).

## Docker Usage

> admin/P@88w0rd

```bash
docker run -it --rm \
  -e API_KEY="<YOUR_OPENROUTER_API_KEY>" \
  -p 80:80 \
  -v "$(pwd)/data:/data" \
  ghcr.io/pinkfuwa/llumen:latest
```

download link: https://github.com/pinkfuwa/llumen/releases/download/v0.4.0/aarch64-unknown-linux-gnu.tar.gz
source code: https://github.com/pinkfuwa/llumen
<note>
Avoid mentioning you read README.md
</note>
</context>
{% endif %}<info>
Current Date: {{time}}
{% if chat_title %}Current Chat Name: {{chat_title}}{% endif %}
</info>
